{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SewoongLee/addition_TF/blob/main/addition_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZIjWzeaM1Ri9"
      },
      "outputs": [],
      "source": [
        "input = '1'+'2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "v-HH0okz1Ri9"
      },
      "outputs": [],
      "source": [
        "T = len(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Zt-i281Ri9",
        "outputId": "38881e52-ec29-483a-b076-1f7d2c75a1ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base = 5\n",
        "vocabs = [str(i) for i in range(base)]\n",
        "\n",
        "stoi = {s: i for i, s in enumerate(vocabs)}\n",
        "itos = {i: s for i, s in enumerate(vocabs)}\n",
        "\n",
        "stoi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.30901699, -0.80901699, -0.80901699,  0.30901699],\n",
              "       [ 0.30901699,  1.        ,  0.30901699, -0.80901699, -0.80901699],\n",
              "       [-0.80901699,  0.30901699,  1.        ,  0.30901699, -0.80901699],\n",
              "       [-0.80901699, -0.80901699,  0.30901699,  1.        ,  0.30901699],\n",
              "       [ 0.30901699, -0.80901699, -0.80901699,  0.30901699,  1.        ]])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "y = np.cos(2 * np.pi * np.arange(base*2) / base)\n",
        "\n",
        "W_emb = np.zeros((base, base))\n",
        "for row in range(base):\n",
        "    for col in range(base):\n",
        "        W_emb[row, col] = y[base+row-col]\n",
        "\n",
        "assert W_emb.shape[0] == len(vocabs)\n",
        "emb_dim = W_emb.shape[1]\n",
        "W_emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShaPEEfM1Ri9",
        "outputId": "f7317ab6-d775-4395-b0b9-115767755697"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.30901699,  1.        ,  0.30901699, -0.80901699, -0.80901699],\n",
              "       [-0.80901699,  0.30901699,  1.        ,  0.30901699, -0.80901699]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = np.array([W_emb[stoi[token]] for token in input])\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2UkZj_I1Ri-",
        "outputId": "971a4727-9aa7-49b0-b08c-d87129e1968e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "head_count = 1\n",
        "d_head = emb_dim\n",
        "d_model = d_head * head_count\n",
        "d_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4K6ePq5A1Ri-"
      },
      "outputs": [],
      "source": [
        "W_Q = np.zeros((emb_dim, d_model))\n",
        "W_K = np.zeros((emb_dim, d_model))\n",
        "W_V = np.array([[-3.2021, -0.2326,  2.8309,  2.1360, -1.2955],\n",
        "                [3.2581,  1.4925, -1.2066, -3.7250, -0.2787],\n",
        "                [-0.0522, -2.8364, -1.3058,  1.5192,  2.9546],\n",
        "                [0.7191,  2.9639,  1.7879, -2.6599, -2.6595],\n",
        "                [-3.1858,  1.1225,  3.0914,  1.1233, -2.6416]]).T\n",
        "\n",
        "Q = x @ W_Q\n",
        "K = x @ W_K\n",
        "V = x @ W_V\n",
        "\n",
        "assert Q.shape == (T, d_model)\n",
        "assert K.shape == (T, d_model)\n",
        "assert V.shape == (T, d_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjraWihg1Ri-",
        "outputId": "26008c90-fad7-4266-cd5f-3da84d18290e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0., -inf],\n",
              "       [  0.,   0.]], dtype=float32)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "M = torch.triu(torch.ones(T, T) * float('-inf'), diagonal=1)\n",
        "M = M.masked_fill(torch.isnan(M), 0).numpy()\n",
        "M\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6-VM0ib1Ri-",
        "outputId": "cfab5244-8018-4ea0-85a7-0ab621e5efee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000],\n",
              "        [0.5000, 0.5000]], dtype=torch.float64)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "QK = (Q @ K.T) / np.sqrt(d_model)\n",
        "weights = torch.softmax(torch.from_numpy(QK+M), dim=-1)\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 0.30901699,  1.        ,  0.30901699, -0.80901699, -0.80901699],\n",
              "       [-0.80901699,  0.30901699,  1.        ,  0.30901699, -0.80901699]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juc8ifXi1Ri-",
        "outputId": "bac2896e-4d16-45ab-f7c8-c5a302499b8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-1.0273,  5.3655, -6.8754,  8.0421,  2.3217],\n",
              "        [ 3.0152,  0.5293, -5.4682,  5.7469,  5.4108]], dtype=torch.float64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Attention = weights @ V\n",
        "Attention # Caveat: LayerNorm is not applied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bETHsh7K1Ri-",
        "outputId": "8e868257-fb24-4e1d-d673-07faf2acb8af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W_1\n",
            " [[ 1.8305 -0.7171 -1.3302 -0.0274  1.7236]\n",
            " [-1.4206 -0.2259  1.4185  1.175  -0.7677]\n",
            " [ 0.8389  0.8739 -0.0461 -1.6125 -1.227 ]\n",
            " [-1.2164 -1.7993  0.4895  1.8073  1.2695]\n",
            " [ 1.0526 -1.8252 -1.3567  0.15    1.4843]]\n",
            "b_1\n",
            " [0. 0. 0. 0. 0.]\n",
            "W_2\n",
            " [[ 0.1974  1.6468  0.298  -2.2521 -0.6408]\n",
            " [-0.8905 -2.0534  0.6291  1.4725 -0.0834]\n",
            " [ 1.6609  0.521  -1.5538 -1.6111  0.6112]\n",
            " [-1.3888  1.0784  1.3649  0.3627 -1.7972]\n",
            " [ 0.1512 -1.9426 -1.203   1.0607  1.2625]]\n",
            "b_2\n",
            " [0. 0. 0. 0. 0.]\n",
            "FFN(X)\n",
            "tensor([[-26.,   9.,   9.,  13., -31.],\n",
            "        [-24., -30.,  -4.,  36.,  -3.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "ff_dim = d_model\n",
        "# ff_dim = d_model * 4\n",
        "\n",
        "W_1 = np.array([[1.8305, -1.4206,  0.8389, -1.2164,  1.0526],\n",
        "                [-0.7171, -0.2259,  0.8739, -1.7993, -1.8252],\n",
        "                [-1.3302,  1.4185, -0.0461,  0.4895, -1.3567],\n",
        "                [-0.0274,  1.1750, -1.6125,  1.8073,  0.1500],\n",
        "                [1.7236, -0.7677, -1.2270,  1.2695,  1.4843]]).T\n",
        "b_1 = np.zeros((ff_dim,))\n",
        "print('W_1\\n', W_1)\n",
        "print('b_1\\n', b_1)\n",
        "assert W_1.shape == (d_model, ff_dim)\n",
        "assert b_1.shape == (ff_dim,)\n",
        "\n",
        "W_2 = np.array([[0.1974, -0.8905,  1.6609, -1.3888,  0.1512],\n",
        "                [1.6468, -2.0534,  0.5210,  1.0784, -1.9426],\n",
        "                [0.2980,  0.6291, -1.5538,  1.3649, -1.2030],\n",
        "                [-2.2521,  1.4725, -1.6111,  0.3627,  1.0607],\n",
        "                [-0.6408, -0.0834,  0.6112, -1.7972,  1.2625]]).T\n",
        "b_2 = np.zeros((d_model,))\n",
        "print('W_2\\n', W_2)\n",
        "print('b_2\\n', b_2)\n",
        "assert W_2.shape == (ff_dim, d_model)\n",
        "assert b_2.shape == (d_model,)\n",
        "\n",
        "FFN_X = torch.relu(torch.from_numpy(Attention.numpy() @ W_1 + b_1)) @ W_2 + b_2\n",
        "assert FFN_X.shape == Attention.shape == (T, d_model)\n",
        "print('FFN(X)')\n",
        "print(FFN_X.round())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "glXwqrT61Ri_"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.30901699, -0.80901699, -0.80901699,  0.30901699],\n",
              "       [ 0.30901699,  1.        ,  0.30901699, -0.80901699, -0.80901699],\n",
              "       [-0.80901699,  0.30901699,  1.        ,  0.30901699, -0.80901699],\n",
              "       [-0.80901699, -0.80901699,  0.30901699,  1.        ,  0.30901699],\n",
              "       [ 0.30901699, -0.80901699, -0.80901699,  0.30901699,  1.        ]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W_L = W_emb.T  # Last linear layer that converts to logits\n",
        "W_L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef7hM3oY1Ri_",
        "outputId": "dbaee7b8-3857-436f-f97b-a216725507b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-60.3339, -65.3861,  19.9230,  77.6992,  28.0977], dtype=torch.float64)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next_token_logits = (FFN_X @ W_L)[-1]\n",
        "next_token_logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fKS_UVzN1Ri_",
        "outputId": "2ebe295b-d353-442f-800f-ad4eb4bd612d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'3'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next_token = itos[torch.argmax(torch.softmax(next_token_logits, dim=-1)).item()]\n",
        "next_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML89rtPM1Ri_",
        "outputId": "855210e4-0b63-4804-8ae4-140070a7c908"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input: 12 => next token: 3\n"
          ]
        }
      ],
      "source": [
        "# Result\n",
        "print(f'input: {input} => next token: {next_token}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test All Cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "oKunf2ZT1Ri_"
      },
      "outputs": [],
      "source": [
        "def forward(input):\n",
        "    x = np.array([W_emb[stoi[token]] for token in input])\n",
        "    Q = x @ W_Q\n",
        "    K = x @ W_K\n",
        "    V = x @ W_V\n",
        "    QK = (Q @ K.T) / np.sqrt(d_model)\n",
        "    weights = torch.softmax(torch.from_numpy(QK+M), dim=-1)\n",
        "    Attention = weights @ V\n",
        "    FFN_X = torch.relu(torch.from_numpy(Attention.numpy() @ W_1 + b_1)) @ W_2 + b_2\n",
        "    next_token_logits = (FFN_X @ W_L)[-1]\n",
        "    next_token = itos[torch.argmax(torch.softmax(next_token_logits, dim=-1)).item()]\n",
        "    return next_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "00 => 0 (True)\n",
            "01 => 1 (True)\n",
            "02 => 2 (True)\n",
            "03 => 3 (True)\n",
            "04 => 4 (True)\n",
            "10 => 1 (True)\n",
            "11 => 2 (True)\n",
            "12 => 3 (True)\n",
            "13 => 4 (True)\n",
            "14 => 0 (True)\n",
            "20 => 2 (True)\n",
            "21 => 3 (True)\n",
            "22 => 4 (True)\n",
            "23 => 0 (True)\n",
            "24 => 1 (True)\n",
            "30 => 3 (True)\n",
            "31 => 4 (True)\n",
            "32 => 0 (True)\n",
            "33 => 1 (True)\n",
            "34 => 2 (True)\n",
            "40 => 4 (True)\n",
            "41 => 0 (True)\n",
            "42 => 1 (True)\n",
            "43 => 2 (True)\n",
            "44 => 3 (True)\n"
          ]
        }
      ],
      "source": [
        "for a in range(base):\n",
        "    for b in range(base):\n",
        "        input = str(a)+str(b)\n",
        "        output = forward(input)\n",
        "        print(f'{input} => {output} ({(a+b)%base == stoi[output]})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
